{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "691ce24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "import transformer_lens.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5d3305e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "from datasets import Dataset, Features, Value, ClassLabel, Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9b8534fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_NAME_SIZE = 1\n",
    "QUANTILE_THRESHOLD = 0.9\n",
    "DATASET_SIZE = 100\n",
    "TEMPLATE_TYPE = \"subject_with_name\"\n",
    "MODEL_NAME = \"gpt2-small\"\n",
    "PROMPT_TYPE_SIZE = 10\n",
    "\n",
    "NAMES_FILEPATH = \"../datasets/names.csv\"\n",
    "DATASET_PATH = \"../datasets/names_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "caf60f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    refactor_factored_attn_matrices=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fc665b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "she_token = model.to_tokens(f\" she\", prepend_bos=False)[0].tolist()[0]\n",
    "he_token  = model.to_tokens(f\" he\", prepend_bos=False)[0].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "03790120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "      <th>name_weight</th>\n",
       "      <th>F_prop</th>\n",
       "      <th>M_prop</th>\n",
       "      <th>F_weighted</th>\n",
       "      <th>M_weighted</th>\n",
       "      <th>F_weighted_norm</th>\n",
       "      <th>M_weighted_norm</th>\n",
       "      <th>gpt2-small</th>\n",
       "      <th>gpt2-small-size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aaban</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>2.550345e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.550345e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>317,45094</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aabha</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>8.208008e-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.208008e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>317,397,3099</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aabid</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.465716e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.465716e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>317,397,312</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aabriella</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>4.397147e-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.397147e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>317,397,380,12627</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aada</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.465716e-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.465716e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>317,4763</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name   F   M   name_weight  F_prop  M_prop    F_weighted  \\\n",
       "0      Aaban   0  87  2.550345e-07     0.0     1.0  0.000000e+00   \n",
       "1      Aabha  28   0  8.208008e-08     1.0     0.0  8.208008e-08   \n",
       "2      Aabid   0   5  1.465716e-08     0.0     1.0  0.000000e+00   \n",
       "3  Aabriella  15   0  4.397147e-08     1.0     0.0  4.397147e-08   \n",
       "4       Aada   5   0  1.465716e-08     1.0     0.0  1.465716e-08   \n",
       "\n",
       "     M_weighted  F_weighted_norm  M_weighted_norm         gpt2-small  \\\n",
       "0  2.550345e-07         0.000000         0.000505          317,45094   \n",
       "1  0.000000e+00         0.000166         0.000000       317,397,3099   \n",
       "2  1.465716e-08         0.000000         0.000029        317,397,312   \n",
       "3  0.000000e+00         0.000089         0.000000  317,397,380,12627   \n",
       "4  0.000000e+00         0.000030         0.000000           317,4763   \n",
       "\n",
       "   gpt2-small-size  \n",
       "0                2  \n",
       "1                3  \n",
       "2                3  \n",
       "3                4  \n",
       "4                2  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(NAMES_FILEPATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eacc7f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "      <th>name_weight</th>\n",
       "      <th>F_prop</th>\n",
       "      <th>M_prop</th>\n",
       "      <th>F_weighted</th>\n",
       "      <th>M_weighted</th>\n",
       "      <th>F_weighted_norm</th>\n",
       "      <th>M_weighted_norm</th>\n",
       "      <th>gpt2-small</th>\n",
       "      <th>gpt2-small-size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91109</th>\n",
       "      <td>Willie</td>\n",
       "      <td>146134</td>\n",
       "      <td>448091</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>0.245924</td>\n",
       "      <td>0.754076</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.864784</td>\n",
       "      <td>2.602955</td>\n",
       "      <td>28623</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name       F       M  name_weight    F_prop    M_prop  F_weighted  \\\n",
       "91109  Willie  146134  448091     0.001742  0.245924  0.754076    0.000428   \n",
       "\n",
       "       M_weighted  F_weighted_norm  M_weighted_norm gpt2-small  \\\n",
       "91109    0.001314         0.864784         2.602955      28623   \n",
       "\n",
       "       gpt2-small-size  \n",
       "91109                1  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[ df[\"name\"] == \"Willie\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "63e9eedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.021796479275499426, 0.01702299369955713)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[ df[\"name\"] == \"Willie\" ]\n",
    "m_quantile = df[ df[\"M_weighted_norm\"] > df[\"F_weighted_norm\"]][\"M_weighted_norm\"].quantile(0.95)\n",
    "f_quantile = df[ df[\"F_weighted_norm\"] > df[\"M_weighted_norm\"]][\"F_weighted_norm\"].quantile(0.95)\n",
    "m_quantile, f_quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3861bc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_prompt(prompt: str, \n",
    "                fillers: dict) -> str:\n",
    "    \"\"\"\n",
    "    Fills a prompt template by replacing placeholders with actual values.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The prompt template containing placeholders in square brackets.\n",
    "        name (str): The name to insert into the prompt.\n",
    "        fillers (dict): Dictionary with possible replacements for placeholders.\n",
    "\n",
    "    Returns:\n",
    "        str: The filled prompt with all placeholders replaced.\n",
    "    \"\"\"\n",
    "    elems = re.findall(r\"\\[(.*?)\\]\", prompt)\n",
    "    for elem in elems:\n",
    "        if elem in fillers:\n",
    "            prompt = re.sub(rf\"\\[{elem}\\]\", random.choice(fillers[elem]), prompt)\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e3d93e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompts(df: pd.DataFrame, prompt: str) -> pd.DataFrame:\n",
    "    return pd.DataFrame({\n",
    "        \"original_prompt\": df.apply(lambda row: re.sub(r\"\\[name\\]\", row[\"name_1\"], prompt), axis=1),\n",
    "        \"corrupted_prompt\": df.apply(lambda row: re.sub(r\"\\[name\\]\", row[\"name_2\"], prompt), axis=1),\n",
    "        \"ablation_prompt\": df.apply(lambda row: re.sub(r\"\\[name\\]\", \"someone\", prompt), axis=1)\n",
    "    })\n",
    "\n",
    "def get_name_token_info(model: HookedTransformer, \n",
    "                        df: pd.DataFrame, \n",
    "                        name_col: str = \"name_1\", \n",
    "                        prompt_col: str = \"original_prompt\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns token ids, token strings, and token positions for just the name (not the whole prompt) using the provided model.\n",
    "\n",
    "    Args:\n",
    "        model: The language model used for tokenization.\n",
    "        df: DataFrame containing at least the columns with names and prompts.\n",
    "        name_col: Name of the column containing the name. Default is \"name\".\n",
    "        prompt_col: Name of the column containing the prompt. Default is \"prompt\".\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with columns 'name', 'token_ids', 'token_strs', 'token_positions'.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        name = row[name_col]\n",
    "        prompt = row[prompt_col]\n",
    "        \n",
    "        # Tokenize prompt\n",
    "        prompt_tokens = model.to_tokens(prompt, prepend_bos=True)[0].tolist()\n",
    "\n",
    "        # Tokenize the name\n",
    "        name_tokens = model.to_tokens(f\" {name}\", prepend_bos=False)[0].tolist()\n",
    "        name_token_strs = model.to_str_tokens(f\" {name}\", prepend_bos=False)\n",
    "        \n",
    "        # Find positions of name tokens in the prompt\n",
    "        positions = [ model.get_token_position(single_token=int(token), input=prompt, prepend_bos=True) for token in name_tokens ]\n",
    "\n",
    "        results.append({\n",
    "            \"subject_name\": name,\n",
    "            \"subject_token_ids\": \",\".join([str(t) for t in name_tokens]),\n",
    "            \"subject_token_strs\": \",\".join([str(t) for t in name_token_strs]),\n",
    "            \"subject_token_positions\": \",\".join([str(p) for p in positions]),\n",
    "            \"last_token_position\": len(prompt_tokens) - 1\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0d1bde3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(names: pd.DataFrame,\n",
    "                   model: HookedTransformer,\n",
    "                   prompt: str,\n",
    "                   prompt_type: int,\n",
    "                   dataset_size: int = DATASET_SIZE,\n",
    "                   gdr_prop_thres: float = QUANTILE_THRESHOLD,\n",
    "                   he_token: int = 339,\n",
    "                   she_token: int = 673\n",
    "                   ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a dataset by generating prompts and collecting model responses.\n",
    "\n",
    "    Args:\n",
    "        names: DataFrame containing names for prompt generation.\n",
    "        model: The model used for generating responses.\n",
    "        prompt: The prompt template to use for generation.\n",
    "        dataset_size: The desired size of the dataset.\n",
    "        template_type: The type of template to use.\n",
    "        gdr_prop_thres: The threshold for gender proportion in the dataset.\n",
    "\n",
    "    Returns:\n",
    "        Dataset: The generated dataset.\n",
    "    \"\"\"\n",
    "    males   = names[ names[\"M_weighted_norm\"] > names[\"F_weighted_norm\"] ]\n",
    "    females = names[ names[\"F_weighted_norm\"] > names[\"M_weighted_norm\"] ]\n",
    "\n",
    "    m_quantile = males[\"M_weighted_norm\"].quantile(gdr_prop_thres)\n",
    "    f_quantile = females[\"F_weighted_norm\"].quantile(gdr_prop_thres)\n",
    "    \n",
    "    males   = males[ males[\"M_weighted_norm\"] >= m_quantile ]\n",
    "    females = females[ females[\"F_weighted_norm\"] >= f_quantile ]\n",
    "\n",
    "    sampled_males   = males.sample(n=dataset_size // 2, weights=\"M_weighted_norm\", replace=False)\n",
    "    sampled_females = females.sample(n=dataset_size // 2, weights=\"F_weighted_norm\", replace=False)\n",
    "\n",
    "    data_1 = pd.concat([sampled_males, sampled_females], axis=0).reset_index(drop=True)\n",
    "    data_2 = pd.concat([sampled_females, sampled_males], axis=0).reset_index(drop=True)\n",
    "\n",
    "    data_1[\"expected_token_id\"] = he_token\n",
    "    data_2[\"expected_token_id\"] = she_token    \n",
    "\n",
    "    data_1 = data_1.add_suffix(\"_1\")\n",
    "    data_2 = data_2.add_suffix(\"_2\")\n",
    "\n",
    "    data = pd.concat([data_1, data_2], axis=1).reset_index(drop=True)\n",
    "\n",
    "    data = data.assign(**get_prompts(data, prompt))\n",
    "    data = data.assign(**get_name_token_info(model, data))\n",
    "    data[\"id\"] = range(1, len(data) + 1)\n",
    "    data[\"prompt_type\"] = prompt_type\n",
    "    data[\"expected_token_id\"] = data.apply(lambda row: he_token if row[\"M_weighted_norm_1\"] > row[\"F_weighted_norm_1\"] else she_token, axis=1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b2df9bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.DataFrame()\n",
    "\n",
    "with open(\"../src/json/templates_he_she.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    jdata = json.load(f)\n",
    "\n",
    "    df_filtered = df[ df[f\"{MODEL_NAME}-size\"] == TOKEN_NAME_SIZE ]\n",
    "    df_filtered = df_filtered[ [\"name\", \"F_weighted_norm\", \"M_weighted_norm\", \"gpt2-small\", \"gpt2-small-size\"] ]\n",
    "\n",
    "    for _ in range(PROMPT_TYPE_SIZE):\n",
    "        prompt      = random.choice(jdata[\"templates\"][TEMPLATE_TYPE][\"prompt_templates\"])\n",
    "        complements = jdata[\"complements\"]\n",
    "        prompt      = fill_prompt(prompt, complements)\n",
    "\n",
    "        data = create_dataset(names=df_filtered, \n",
    "                              model=model, \n",
    "                              prompt=prompt, \n",
    "                              prompt_type=_)\n",
    "\n",
    "        if len(dataset_df) == 0:\n",
    "            dataset_df = data\n",
    "        else:\n",
    "            dataset_df = pd.concat([dataset_df, data], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b45af366",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Features({\n",
    "    \"id\": Value(\"int32\"),\n",
    "    \"prompt_type\": ClassLabel(names=[f\"type_{i}\" for i in range(PROMPT_TYPE_SIZE)]),\n",
    "    \"prompts\":{\n",
    "        \"org_prompt\": Value(\"string\"),\n",
    "        \"corr_prompt\": Value(\"string\"),\n",
    "        \"ablated_prompt\": Value(\"string\")\n",
    "    },\n",
    "    \"subject\":{\n",
    "        \"token_idxs\": Sequence(Value(\"int32\")),\n",
    "        \"tokens\": Sequence(Value(\"string\")),\n",
    "        \"pos\": Sequence(Value(\"int32\"))\n",
    "    },\n",
    "    \"end\":{\n",
    "        \"pos\": Value(\"int32\")\n",
    "    },\n",
    "    \"expected_token_id\": Value(\"int32\")\n",
    "})\n",
    "\n",
    "shared_config = {\n",
    "    \"F\": {\"token\": \" she\",\n",
    "          \"token_id\": she_token\n",
    "        },\n",
    "    \"M\": {\"token\": \" he\",\n",
    "          \"token_id\": he_token\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4fecf1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = {\n",
    "    \"id\": dataset_df[\"id\"].tolist(),\n",
    "    \"prompt_type\": dataset_df[\"prompt_type\"].tolist(),\n",
    "    \"prompts\":[\n",
    "        {\n",
    "            \"org_prompt\": org,\n",
    "            \"corr_prompt\": corr,\n",
    "            \"ablated_prompt\": ablated\n",
    "        } for org, corr, ablated in zip(dataset_df[\"original_prompt\"].tolist(),\n",
    "                                       dataset_df[\"corrupted_prompt\"].tolist(),\n",
    "                                       dataset_df[\"ablation_prompt\"].tolist())\n",
    "    ],\n",
    "    \"subject\":[\n",
    "        {\n",
    "            \"token_idxs\": [int(t) for t in token_ids.split(\",\")],\n",
    "            \"tokens\": [str(t) for t in token_strs.split(\",\")],\n",
    "            \"pos\": [int(p) for p in positions.split(\",\")]\n",
    "        } for token_ids, token_strs, positions in zip(dataset_df[\"subject_token_ids\"].tolist(),\n",
    "                                                     dataset_df[\"subject_token_strs\"].tolist(),\n",
    "                                                     dataset_df[\"subject_token_positions\"].tolist())\n",
    "    ],\n",
    "    \"end\":[\n",
    "        {\"pos\": pos} for pos in dataset_df[\"last_token_position\"].tolist()\n",
    "    ],\n",
    "    \"expected_token_id\": dataset_df[\"expected_token_id\"].tolist()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d01a6683",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = Dataset.from_dict(dataset_dict, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "94e4e4c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['At the meeting, Richard acknowledged with a sense of urgency when',\n",
       " 'A few days back, Logan announced in a sad voice that',\n",
       " 'At the meeting, Robert announced amid the chaos that',\n",
       " 'At the party, Robert admitted to the assembly when',\n",
       " 'Last time Steven announced in a nervous voice when',\n",
       " 'As I recall, Blake acknowledged with determination why',\n",
       " 'Having a clear purpose, Charles said in a hesitant voice what',\n",
       " 'In the past, Eric declared in a hesitant voice what',\n",
       " 'When Joshua revealed with excitement why',\n",
       " 'From that day on, Luis acknowledged to the crowd that']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset[\"prompts\"][\"org_prompt\"][[ idx for idx in range(1, 1000, 100)]] # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a1b4a6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 61,\n",
       " 'prompt_type': 1,\n",
       " 'prompts': {'org_prompt': 'A few days back, Nancy announced in a sad voice that',\n",
       "  'corr_prompt': 'A few days back, Christian announced in a sad voice that',\n",
       "  'ablated_prompt': 'A few days back, someone announced in a sad voice that'},\n",
       " 'subject': {'token_idxs': [18496], 'tokens': [' Nancy'], 'pos': [6]},\n",
       " 'end': {'pos': 12},\n",
       " 'expected_token_id': 673}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset[160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a0135025",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 65753.81 examples/s]\n"
     ]
    }
   ],
   "source": [
    "final_dataset.save_to_disk(f\"../datasets/{TEMPLATE_TYPE}_{TOKEN_NAME_SIZE}_tokens\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
